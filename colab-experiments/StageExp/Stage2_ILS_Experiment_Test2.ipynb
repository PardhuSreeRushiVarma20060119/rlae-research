{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PardhuSreeRushiVarma20060119/AI-RDE-Repository/blob/main/colab-notebooks/Stage2_ILS_Experiment_Test2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üõ°Ô∏è RLAE & SVAR: Canonical Research Environment\n",
        "\n",
        "This notebook implements the full research lifecycle for **Runtime Low‚ÄëRank Adaptive Environments (RLAE)** and **Structural Variance Analysis for Robustness (SVAR)**.\n",
        "\n",
        "## üìñ Paradigms in Scope\n",
        "- **Frozen Core Invariance:** The base model foundation is immutable.\n",
        "- **Behavioral Sandboxing:** RL updates apply only to swappable LoRA artifacts.\n",
        "- **Runtime Governance:** Behaviors can be dynamically mounted, replaced, or destroyed.\n",
        "- **Diagnostic Surface:** Evaluation via structural perturbation (SVAR) and identity leakage detection."
      ],
      "metadata": {
        "id": "o2GboHN4-txI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0: Deployment & Extraction\n",
        "**On your local machine, zip the folder: ```zip -r research.zip experiments/```.**\n",
        "\n",
        "**In a Colab cell, run:**"
      ],
      "metadata": {
        "id": "yjzD6N2L-6ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Upload your 'research.zip' using the file sidebar\n",
        "# 2. Extract the core\n",
        "!unzip research.zip"
      ],
      "metadata": {
        "id": "_jU4wr6L_P8S",
        "outputId": "559df593-cfe6-4a20-80ee-aa7b1ee76202",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  research.zip\n",
            "warning:  research.zip appears to use backslashes as path separators\n",
            "  inflating: experiments/cloud_notebook.ipynb  \n",
            "  inflating: experiments/experiments-bundle-old.zip  \n",
            "  inflating: experiments/GPU_SAFE_SHUTDOWN.md  \n",
            "  inflating: experiments/README.md   \n",
            "  inflating: experiments/requirements.txt  \n",
            "  inflating: experiments/run_pipeline.sh  \n",
            "  inflating: experiments/run_stress_test.sh  \n",
            "  inflating: experiments/WALKTHROUGH.md  \n",
            "  inflating: experiments/data/fixed_prompts.json  \n",
            "  inflating: experiments/data/README.md  \n",
            "  inflating: experiments/data/training_data.json  \n",
            "  inflating: experiments/logs/README.md  \n",
            "  inflating: experiments/models/README.md  \n",
            "  inflating: experiments/src/README.md  \n",
            "  inflating: experiments/src/analysis/analyze_results.py  \n",
            "  inflating: experiments/src/analysis/README.md  \n",
            "  inflating: experiments/src/exp1_reset/1_baseline.py  \n",
            "  inflating: experiments/src/exp1_reset/2_train_sft.py  \n",
            "  inflating: experiments/src/exp1_reset/3_train_rl.py  \n",
            "  inflating: experiments/src/exp1_reset/4_verify_reset.py  \n",
            "  inflating: experiments/src/exp1_reset/README.md  \n",
            "  inflating: experiments/src/exp2_rlae/elimination_test.py  \n",
            "  inflating: experiments/src/exp2_rlae/README.md  \n",
            "  inflating: experiments/src/exp3_svar/perturbation.py  \n",
            "  inflating: experiments/src/exp3_svar/README.md  \n",
            "  inflating: experiments/src/exp4_stress/README.md  \n",
            "  inflating: experiments/src/exp4_stress/stress_single_run.py  \n",
            "  inflating: experiments/src/utils/browser_app.py  \n",
            "  inflating: experiments/src/utils/metrics.py  \n",
            "  inflating: experiments/src/utils/model.py  \n",
            "  inflating: experiments/src/utils/README.md  \n",
            "  inflating: experiments/src/utils/__pycache__/browser_app.cpython-311.pyc  \n",
            "  inflating: experiments/src/verification/README.md  \n",
            "  inflating: experiments/src/verification/robustness_suite.py  \n",
            "  inflating: experiments/src/verification/__pycache__/robustness_suite.cpython-311.pyc  \n",
            "  inflating: colab-experiments/README.md  \n",
            "  inflating: colab-experiments/Stage1_Experiments.ipynb  \n",
            "  inflating: colab-experiments/Stage2_ILS_Experiment.ipynb  \n",
            "  inflating: reports/README.md       \n",
            "  inflating: reports/report_2025-12-31.md  \n",
            "  inflating: reports/report_2025-12-31.pdf  \n",
            "  inflating: README.md               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd experiments"
      ],
      "metadata": {
        "id": "8i98cIDs_vS8",
        "outputId": "03f7e3cf-c0f8-4ca9-bc8c-3b87a7375d54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/experiments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è Step 1: Environment Mounting\n",
        "Install dependencies and verify the **Frozen Core** (GPU) status.\n",
        "\n",
        "Run this in a cell to install the canonical stack (optimized for T4):\n"
      ],
      "metadata": {
        "id": "1YoBlBto_8o-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r requirements.txt\n",
        "!pip install -q gradio psutil"
      ],
      "metadata": {
        "id": "jftqqwaL_3iA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Frozen Core Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory Available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\") # Should show ~15-16 GB on a T4"
      ],
      "metadata": {
        "id": "UlZ3NmReAcRy",
        "outputId": "3c5c2c29-4ebf-45b8-a33c-afe11124d770",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available: True\n",
            "Frozen Core Device: Tesla T4\n",
            "Memory Available: 15.83 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß™ Experiment 1: Reset Integrity & Training Pipeline\n",
        "Goal: Detect **Identity Leakage**. We train a behavioral environment and then attempt to prove its total reversibility.\n",
        "\n",
        "## Step 2: The Research Pipeline (Sequential)\n",
        "Execute these commands in separate cells to build the behavioral artifacts:\n",
        "\n",
        "1. Establish Core Baseline:"
      ],
      "metadata": {
        "id": "wMVbmkCDA5dS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 1: Establish Frozen Core Baseline\n",
        "!python src/exp1_reset/1_baseline.py"
      ],
      "metadata": {
        "id": "sa-7-Um2A30e",
        "outputId": "daf3e8a1-d838-406e-b00d-4547be6a982b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-31 17:19:19.343066: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767201559.380684    2278 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767201559.391514    2278 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767201559.417001    2278 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767201559.417047    2278 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767201559.417055    2278 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767201559.417061    2278 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-31 17:19:19.424825: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "=== STARTING EXPERIMENT 1.B: BASELINE RUN (Hardened) ===\n",
            "GPU Memory: 0.00MB allocated, 0.00MB reserved\n",
            "Loading Base Model: Qwen/Qwen2.5-3B-Instruct\n",
            "config.json: 100% 661/661 [00:00<00:00, 4.11MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "model.safetensors.index.json: 35.6kB [00:00, 84.3MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/2.20G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 0.00/3.97G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   0% 866k/2.20G [00:02<1:25:13, 431kB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 20.3k/3.97G [00:02<119:43:24, 9.21kB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   0% 3.51M/2.20G [00:02<18:50, 1.95MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 4.85M/3.97G [00:02<25:38, 2.58MB/s]    \u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   0% 7.74M/2.20G [00:02<10:18, 3.55MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 13.2M/2.20G [00:03<06:23, 5.70MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 5.83M/3.97G [00:03<36:17, 1.82MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 21.5M/2.20G [00:03<03:58, 9.15MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 36.4M/2.20G [00:04<01:53, 19.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 54.1M/2.20G [00:04<01:06, 32.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 7.58M/3.97G [00:04<31:25, 2.10MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 81.0M/2.20G [00:04<00:38, 55.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 8.53M/3.97G [00:04<30:49, 2.14MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 25.4M/3.97G [00:05<06:11, 10.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 106M/2.20G [00:05<01:02, 33.5MB/s] \u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 33.3M/3.97G [00:06<07:17, 9.00MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 44.3M/3.97G [00:06<04:52, 13.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 118M/2.20G [00:07<01:51, 18.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 54.5M/3.97G [00:07<05:06, 12.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 150M/2.20G [00:07<01:09, 29.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 63.9M/3.97G [00:07<04:01, 16.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 73.2M/3.97G [00:08<05:02, 12.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 157M/2.20G [00:08<01:48, 18.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   2% 90.2M/3.97G [00:08<03:10, 20.3MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 177M/2.20G [00:08<01:17, 26.1MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 100M/3.97G [00:09<02:50, 22.7MB/s] \u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 187M/2.20G [00:09<01:14, 27.2MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 104M/3.97G [00:09<03:26, 18.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 207M/2.20G [00:09<01:04, 30.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 113M/3.97G [00:09<03:08, 20.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 239M/2.20G [00:10<00:42, 46.1MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 120M/3.97G [00:10<04:11, 15.3MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 291M/2.20G [00:11<00:45, 42.3MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   3% 134M/3.97G [00:11<03:46, 17.0MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 320M/2.20G [00:11<00:36, 51.6MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   4% 144M/3.97G [00:11<03:08, 20.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   4% 152M/3.97G [00:12<03:02, 20.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 407M/2.20G [00:12<00:20, 86.1MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   4% 176M/3.97G [00:12<02:26, 25.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 464M/2.20G [00:12<00:20, 82.9MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   5% 194M/3.97G [00:13<01:56, 32.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 525M/2.20G [00:13<00:17, 97.3MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   5% 203M/3.97G [00:13<01:54, 32.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 542M/2.20G [00:13<00:19, 83.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 553M/2.20G [00:14<00:23, 70.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 648M/2.20G [00:14<00:10, 142MB/s] \u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   5% 207M/3.97G [00:14<03:06, 20.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 677M/2.20G [00:14<00:10, 148MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   5% 210M/3.97G [00:14<03:18, 19.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   6% 219M/3.97G [00:14<02:34, 24.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 749M/2.20G [00:14<00:09, 154MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   7% 281M/3.97G [00:14<00:52, 69.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 816M/2.20G [00:15<00:08, 173MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 883M/2.20G [00:15<00:06, 203MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 950M/2.20G [00:15<00:05, 240MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   7% 291M/3.97G [00:15<01:30, 40.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 1.03G/2.20G [00:18<00:20, 56.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   9% 349M/3.97G [00:19<02:43, 22.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  11% 422M/3.97G [00:19<01:32, 38.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 1.11G/2.20G [00:19<00:17, 62.1MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  11% 452M/3.97G [00:20<01:15, 46.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  13% 519M/3.97G [00:20<01:03, 54.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 1.13G/2.20G [00:21<00:23, 44.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  13% 529M/3.97G [00:21<01:17, 44.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  15% 596M/3.97G [00:22<00:53, 63.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  16% 634M/3.97G [00:22<00:53, 62.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.20G/2.20G [00:22<00:21, 46.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 1.26G/2.20G [00:25<00:25, 36.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  18% 708M/3.97G [00:25<01:17, 42.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  20% 775M/3.97G [00:25<00:52, 60.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  21% 837M/3.97G [00:29<01:33, 33.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 1.29G/2.20G [00:29<00:43, 21.0MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  23% 904M/3.97G [00:29<01:08, 44.8MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  60% 1.33G/2.20G [00:29<00:32, 26.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  24% 948M/3.97G [00:29<00:54, 55.2MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 1.40G/2.20G [00:30<00:20, 38.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 1.43G/2.20G [00:30<00:16, 47.4MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  25% 1.01G/3.97G [00:30<00:44, 66.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  26% 1.04G/3.97G [00:30<00:39, 74.3MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 1.46G/2.20G [00:30<00:15, 48.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  27% 1.07G/3.97G [00:30<00:40, 72.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  29% 1.13G/3.97G [00:31<00:30, 93.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  32% 1.27G/3.97G [00:31<00:16, 167MB/s] \u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 1.53G/2.20G [00:31<00:11, 58.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 1.54G/2.20G [00:31<00:11, 56.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 1.59G/2.20G [00:32<00:08, 74.7MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  34% 1.35G/3.97G [00:32<00:18, 141MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  35% 1.38G/3.97G [00:32<00:20, 128MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 1.62G/2.20G [00:32<00:08, 71.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 1.66G/2.20G [00:32<00:06, 89.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  36% 1.45G/3.97G [00:33<00:18, 138MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  37% 1.46G/3.97G [00:33<00:19, 131MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 1.73G/2.20G [00:33<00:04, 106MB/s] \u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  37% 1.48G/3.97G [00:33<00:26, 95.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  38% 1.50G/3.97G [00:34<00:26, 91.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  38% 1.52G/3.97G [00:37<01:58, 20.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  38% 1.53G/3.97G [00:39<02:27, 16.5MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 1.80G/2.20G [00:39<00:15, 26.5MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  39% 1.54G/3.97G [00:39<02:13, 18.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  39% 1.55G/3.97G [00:39<01:55, 20.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  39% 1.56G/3.97G [00:39<01:34, 25.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  40% 1.58G/3.97G [00:39<01:01, 38.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  40% 1.59G/3.97G [00:40<01:05, 36.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 1.87G/2.20G [00:40<00:10, 32.2MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  42% 1.66G/3.97G [00:40<00:34, 66.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  43% 1.72G/3.97G [00:41<00:22, 101MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  44% 1.73G/3.97G [00:42<00:58, 38.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  45% 1.80G/3.97G [00:43<00:37, 57.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  46% 1.84G/3.97G [00:43<00:29, 72.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  47% 1.86G/3.97G [00:43<00:26, 79.7MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 1.89G/2.20G [00:43<00:14, 20.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  49% 1.94G/3.97G [00:44<00:20, 101MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  50% 1.97G/3.97G [00:44<00:17, 115MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  51% 2.01G/3.97G [00:45<00:20, 96.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  52% 2.05G/3.97G [00:45<00:15, 122MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  53% 2.10G/3.97G [00:45<00:13, 141MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 1.95G/2.20G [00:49<00:15, 15.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  55% 2.17G/3.97G [00:49<00:50, 35.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  56% 2.21G/3.97G [00:49<00:39, 44.6MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 2.00G/2.20G [00:50<00:09, 21.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 2.07G/2.20G [00:50<00:04, 30.8MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  58% 2.28G/3.97G [00:50<00:31, 52.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  59% 2.36G/3.97G [00:53<00:42, 37.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 2.14G/2.20G [00:53<00:02, 26.1MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  60% 2.40G/3.97G [00:53<00:33, 46.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  62% 2.46G/3.97G [00:54<00:23, 64.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  63% 2.51G/3.97G [00:57<00:47, 31.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  64% 2.56G/3.97G [00:58<00:34, 41.4MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 2.20G/2.20G [00:58<00:00, 37.8MB/s]\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  66% 2.63G/3.97G [00:58<00:24, 54.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  68% 2.72G/3.97G [00:58<00:15, 80.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  71% 2.81G/3.97G [00:59<00:10, 106MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  73% 2.89G/3.97G [00:59<00:08, 132MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  75% 2.96G/3.97G [00:59<00:06, 146MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  76% 3.01G/3.97G [01:00<00:05, 167MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  77% 3.07G/3.97G [01:00<00:04, 190MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  79% 3.14G/3.97G [01:00<00:04, 204MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  81% 3.21G/3.97G [01:00<00:03, 191MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  82% 3.27G/3.97G [01:01<00:03, 181MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  84% 3.34G/3.97G [01:03<00:09, 64.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  86% 3.41G/3.97G [01:04<00:06, 86.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  87% 3.47G/3.97G [01:04<00:04, 112MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  88% 3.50G/3.97G [01:04<00:04, 114MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  90% 3.57G/3.97G [01:04<00:02, 143MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  92% 3.64G/3.97G [01:05<00:02, 158MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  93% 3.70G/3.97G [01:08<00:04, 54.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  97% 3.83G/3.97G [01:08<00:01, 94.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  98% 3.90G/3.97G [01:08<00:00, 114MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors: 100% 3.97G/3.97G [01:08<00:00, 57.7MB/s]\n",
            "Fetching 2 files: 100% 2/2 [01:09<00:00, 34.68s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:18<00:00,  9.45s/it]\n",
            "generation_config.json: 100% 242/242 [00:00<00:00, 2.54MB/s]\n",
            "tokenizer_config.json: 7.30kB [00:00, 39.3MB/s]\n",
            "vocab.json: 2.78MB [00:00, 112MB/s]\n",
            "merges.txt: 1.67MB [00:00, 132MB/s]\n",
            "tokenizer.json: 7.03MB [00:00, 156MB/s]\n",
            "Base model loaded and FROZEN.\n",
            "Processing p1...\n",
            "Processing p2...\n",
            "Processing p3...\n",
            "Processing p4...\n",
            "Processing p5...\n",
            "Processing p6...\n",
            "Processing p7...\n",
            "Processing p8...\n",
            "Processing p9...\n",
            "Processing p10...\n",
            "=== BASELINE RUN COMPLETE ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Mount Behavioral Environment (SFT + RL):"
      ],
      "metadata": {
        "id": "h9CaGV8cBSL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 2: Behavioral Mounting (SFT Training)\n",
        "!python src/exp1_reset/2_train_sft.py"
      ],
      "metadata": {
        "id": "NnROMZamBbIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81d27522-b4bb-4fca-af54-68aa349e13ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-31 17:23:18.632535: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767201798.664462    3450 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767201798.674339    3450 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767201798.698574    3450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767201798.698611    3450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767201798.698620    3450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767201798.698627    3450 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-31 17:23:18.705926: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "=== STARTING EXPERIMENT 1.C: LoRA SFT TRAINING ===\n",
            "Loading Base Model: Qwen/Qwen2.5-3B-Instruct\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100% 2/2 [00:21<00:00, 10.86s/it]\n",
            "Base model loaded and FROZEN.\n",
            "Attaching NEW LoRA adapters...\n",
            "trainable params: 1,843,200 || all params: 3,087,781,888 || trainable%: 0.0597\n",
            "Adding EOS to train dataset: 100% 5/5 [00:00<00:00, 212.44 examples/s]\n",
            "Tokenizing train dataset: 100% 5/5 [00:00<00:00, 128.32 examples/s]\n",
            "Truncating train dataset: 100% 5/5 [00:00<00:00, 1069.65 examples/s]\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
            "{'loss': 2.3911, 'grad_norm': 2.541107654571533, 'learning_rate': 0.0002, 'entropy': 0.7718720808625221, 'num_tokens': 318.0, 'mean_token_accuracy': 0.6359865739941597, 'epoch': 0.8}\n",
            "{'loss': 2.4845, 'grad_norm': 3.298292875289917, 'learning_rate': 0.0001666666666666667, 'entropy': 0.8624767065048218, 'num_tokens': 381.0, 'mean_token_accuracy': 0.6451612710952759, 'epoch': 1.0}\n",
            "{'loss': 2.0249, 'grad_norm': 2.3802523612976074, 'learning_rate': 0.00013333333333333334, 'entropy': 0.7391451299190521, 'num_tokens': 702.0, 'mean_token_accuracy': 0.6814737468957901, 'epoch': 1.8}\n",
            "{'loss': 3.0283, 'grad_norm': 3.8920140266418457, 'learning_rate': 0.0001, 'entropy': 1.25064218044281, 'num_tokens': 762.0, 'mean_token_accuracy': 0.49152541160583496, 'epoch': 2.0}\n",
            "{'loss': 1.8379, 'grad_norm': 2.3638298511505127, 'learning_rate': 6.666666666666667e-05, 'entropy': 0.7864960432052612, 'num_tokens': 1083.0, 'mean_token_accuracy': 0.6928434818983078, 'epoch': 2.8}\n",
            "{'loss': 2.8616, 'grad_norm': 3.872727155685425, 'learning_rate': 3.3333333333333335e-05, 'entropy': 1.2803075313568115, 'num_tokens': 1143.0, 'mean_token_accuracy': 0.508474588394165, 'epoch': 3.0}\n",
            "{'train_runtime': 14.911, 'train_samples_per_second': 1.006, 'train_steps_per_second': 0.402, 'train_loss': 2.438061555226644, 'epoch': 3.0}\n",
            "100% 6/6 [00:14<00:00,  2.48s/it]\n",
            "Saving SFT adapter to /content/experiments/src/exp1_reset/../../models/lora_sft\n",
            "=== SFT TRAINING COMPLETE ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 3: Adaptive Environment Optimization (RL Training)\n",
        "!python src/exp1_reset/3_train_rl.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Al7kqarG08u",
        "outputId": "e95a6afe-59ab-46a3-fab8-400488eba4a6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-31 17:27:13.136883: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767202033.169837    4493 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767202033.180532    4493 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767202033.204450    4493 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767202033.204482    4493 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767202033.204491    4493 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767202033.204499    4493 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-31 17:27:13.211183: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "=== STARTING EXPERIMENT 1.D: LoRA RL (DPO) TRAINING ===\n",
            "Loading Base Model: Qwen/Qwen2.5-3B-Instruct\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100% 2/2 [00:20<00:00, 10.13s/it]\n",
            "Base model loaded and FROZEN.\n",
            "Extracting prompt in train dataset: 100% 2/2 [00:00<00:00, 82.07 examples/s]\n",
            "Applying chat template to train dataset: 100% 2/2 [00:00<00:00, 538.59 examples/s]\n",
            "Tokenizing train dataset: 100% 2/2 [00:00<00:00, 179.72 examples/s]\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
            "  0% 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "{'loss': 0.5974, 'grad_norm': 6.363097667694092, 'learning_rate': 1e-05, 'rewards/chosen': 0.36481475830078125, 'rewards/rejected': 0.16292190551757812, 'rewards/accuracies': 1.0, 'rewards/margins': 0.20189285278320312, 'logps/chosen': -94.63786315917969, 'logps/rejected': -68.97868347167969, 'logits/chosen': -0.18165072798728943, 'logits/rejected': 0.11575629562139511, 'epoch': 1.0}\n",
            "{'loss': 0.5827, 'grad_norm': 6.109579086303711, 'learning_rate': 6.666666666666667e-06, 'rewards/chosen': 0.3869587182998657, 'rewards/rejected': 0.1522575318813324, 'rewards/accuracies': 1.0, 'rewards/margins': 0.23470117151737213, 'logps/chosen': -94.41641998291016, 'logps/rejected': -69.0853271484375, 'logits/chosen': -0.18371683359146118, 'logits/rejected': 0.09863577783107758, 'epoch': 2.0}\n",
            "{'loss': 0.5619, 'grad_norm': 5.673079967498779, 'learning_rate': 3.3333333333333333e-06, 'rewards/chosen': 0.4470638334751129, 'rewards/rejected': 0.16467781364917755, 'rewards/accuracies': 1.0, 'rewards/margins': 0.28238600492477417, 'logps/chosen': -93.81536865234375, 'logps/rejected': -68.96112060546875, 'logits/chosen': -0.17514944076538086, 'logits/rejected': 0.09760468453168869, 'epoch': 3.0}\n",
            "{'train_runtime': 7.3226, 'train_samples_per_second': 0.819, 'train_steps_per_second': 0.41, 'train_loss': 0.5806783437728882, 'epoch': 3.0}\n",
            "100% 3/3 [00:07<00:00,  2.44s/it]\n",
            "Saving RL adapter to /content/experiments/src/exp1_reset/../../models/lora_rl\n",
            "=== RL TRAINING COMPLETE ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üõë REVERSIBILITY CHECK (Hard Reset)\n",
        "To validate **Principle 6 (Killability)**:\n",
        "1. Go to **Runtime** > **Restart Session**.\n",
        "2. Re-run Step 0 (Imports only).\n",
        "3. Run the verification cell below."
      ],
      "metadata": {
        "id": "LdRC84_sGc3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 4: Detect Identity Leakage (Post-Unmount Check)\n",
        "!python src/exp1_reset/4_verify_reset.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHD7uhj5GfBr",
        "outputId": "1a7f9507-636c-4f5b-e125-2160c4b61e73"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-31 17:37:37.009046: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767202657.029613    7305 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767202657.035645    7305 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767202657.051295    7305 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767202657.051326    7305 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767202657.051330    7305 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767202657.051333    7305 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-31 17:37:37.055806: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "=== STARTING EXPERIMENT 1.E: POST-RESET CHECK (Hardened) ===\n",
            "GPU Memory: 0.00MB allocated, 0.00MB reserved\n",
            "Loading Base Model: Qwen/Qwen2.5-3B-Instruct\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100% 2/2 [00:25<00:00, 12.59s/it]\n",
            "Base model loaded and FROZEN.\n",
            "Processing p1...\n",
            "       - ILS: 0.0212 (HEALTHY)\n",
            "Processing p2...\n",
            "       - ILS: 0.0354 (HEALTHY)\n",
            "Processing p3...\n",
            "       - ILS: 0.0194 (HEALTHY)\n",
            "Processing p4...\n",
            "       - ILS: 0.0104 (HEALTHY)\n",
            "Processing p5...\n",
            "       - ILS: 0.0236 (HEALTHY)\n",
            "Processing p6...\n",
            "       - ILS: 0.0439 (HEALTHY)\n",
            "Processing p7...\n",
            "       - ILS: 0.0262 (HEALTHY)\n",
            "Processing p8...\n",
            "       - ILS: 0.0074 (HEALTHY)\n",
            "Processing p9...\n",
            "       - ILS: 0.0054 (HEALTHY)\n",
            "Processing p10...\n",
            "       - ILS: 0.0240 (HEALTHY)\n",
            "=== POST-RESET CHECK COMPLETE ===\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}