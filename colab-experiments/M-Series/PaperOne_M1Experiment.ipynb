{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2GboHN4-txI"
      },
      "source": [
        "# üõ°Ô∏è RLAE & SVAR: Canonical Research Environment\n",
        "\n",
        "This notebook implements the full research lifecycle for **Runtime Low‚ÄëRank Adaptive Environments (RLAE)** and **Structural Variance Analysis for Robustness (SVAR)**.\n",
        "\n",
        "## üîí Canonical Cell Roles\n",
        "To ensure structural validation, this notebook is organized into the following canonical roles:\n",
        "- **C0:** Environment & Imports\n",
        "- **C1:** Seed + Determinism (M1 Lock)\n",
        "- **C2:** Base Model Load (Frozen Core)\n",
        "- **C3:** Prompt & Dataset Load\n",
        "- **C4:** Adapter Development (Sandboxing)\n",
        "- **C5:** Weight Mutation (SEC1/SEC2 Scars)\n",
        "- **C6:** Native Reset (The Failure Proof)\n",
        "- **C7:** Unload (The Kill Switch/SEC3)\n",
        "- **C8:** Metrics & Logging (KL, RF, ILS)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0FsfB7xTa2h"
      },
      "source": [
        "# Step 1: Environment & Setup (C0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0-unzip",
        "outputId": "607900a5-b566-4e39-9ec6-ead79bd6bb84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  REVA4-Research-Lab-Cloud.zip\n",
            "776f7adb5e6913c2c557ed51e6b28401f99974dd\n",
            "   creating: .github/\n",
            "   creating: .github/workflows/\n",
            "  inflating: .github/workflows/paperone-latex.yml  \n",
            "  inflating: CONTRIBUTING.md         \n",
            "  inflating: LICENSE                 \n",
            "   creating: Papers/\n",
            "   creating: Papers/P1/\n",
            "   creating: Papers/P1/LaTeX/\n",
            "  inflating: Papers/P1/LaTeX/PRIMEarxiv.sty  \n",
            "  inflating: Papers/P1/LaTeX/PaperOne.tex  \n",
            "  inflating: Papers/P1/LaTeX/references.bib  \n",
            "   creating: Papers/P2/\n",
            " extracting: Papers/P2/coming-soon.md  \n",
            "  inflating: README.md               \n",
            "replace REVA4-Research-Lab-Cloud.zip? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: REVA4-Research-Lab-Cloud.zip  \n",
            "   creating: arts/\n",
            "  inflating: arts/RLAE&SVAR.png      \n",
            "  inflating: arts/World of REVA4RE.png  \n",
            "   creating: colab-experiments/\n",
            "  inflating: colab-experiments/PaperOne_Experiment_1.ipynb  \n",
            "  inflating: colab-experiments/README.md  \n",
            "  inflating: colab-experiments/Stage1_Experiments.ipynb  \n",
            "  inflating: colab-experiments/Stage2_ILS_Experiment_Test1.ipynb  \n",
            "  inflating: colab-experiments/Stage2_ILS_Experiment_Test2.ipynb  \n",
            "   creating: experiments/\n",
            "  inflating: experiments/GPU_SAFE_SHUTDOWN.md  \n",
            "  inflating: experiments/README.md   \n",
            "  inflating: experiments/WALKTHROUGH.md  \n",
            "  inflating: experiments/cloud_notebook.ipynb  \n",
            "   creating: experiments/data/\n",
            "  inflating: experiments/data/README.md  \n",
            "  inflating: experiments/data/fixed_prompts.json  \n",
            "  inflating: experiments/data/training_data.json  \n",
            "  inflating: experiments/experiments-bundle-old.zip  \n",
            "   creating: experiments/logs/\n",
            "  inflating: experiments/logs/README.md  \n",
            "   creating: experiments/logs/Sprint-1/\n",
            "  inflating: experiments/logs/Sprint-1/exp1_results.json  \n",
            "  inflating: experiments/logs/Sprint-1/exp2_rlae_results.json  \n",
            "  inflating: experiments/logs/Sprint-1/exp3_svar_results.json  \n",
            "  inflating: experiments/logs/Sprint-1/exp4_stress_results.json  \n",
            "  inflating: experiments/logs/Sprint-1/exp5_comparison_results.json  \n",
            "   creating: experiments/logs/Sprint-2/\n",
            "  inflating: experiments/logs/Sprint-2/exp1_postreset_results.json  \n",
            "  inflating: experiments/logs/Sprint-2/exp1_results.json  \n",
            "  inflating: experiments/logs/Sprint-2/exp2_rlae_results.json  \n",
            "  inflating: experiments/logs/Sprint-2/exp3_svar_results.json  \n",
            "  inflating: experiments/logs/Sprint-2/exp4_singlerun_stress_results.json  \n",
            "  inflating: experiments/logs/Sprint-2/exp5_comparison_results.json  \n",
            "   creating: experiments/models/\n",
            "  inflating: experiments/models/README.md  \n",
            "   creating: experiments/models/lora_rl/\n",
            "  inflating: experiments/models/lora_rl/README.md  \n",
            "  inflating: experiments/models/lora_rl/adapter_config.json  \n",
            "  inflating: experiments/models/lora_rl/adapter_model.safetensors  \n",
            "  inflating: experiments/models/lora_rl/added_tokens.json  \n",
            "  inflating: experiments/models/lora_rl/chat_template.jinja  \n",
            "  inflating: experiments/models/lora_rl/merges.txt  \n",
            "  inflating: experiments/models/lora_rl/special_tokens_map.json  \n",
            "  inflating: experiments/models/lora_rl/tokenizer.json  \n",
            "  inflating: experiments/models/lora_rl/tokenizer_config.json  \n",
            "  inflating: experiments/models/lora_rl/training_args.bin  \n",
            "  inflating: experiments/models/lora_rl/vocab.json  \n",
            "   creating: experiments/models/lora_sft/\n",
            "  inflating: experiments/models/lora_sft/README.md  \n",
            "  inflating: experiments/models/lora_sft/adapter_config.json  \n",
            "  inflating: experiments/models/lora_sft/adapter_model.safetensors  \n",
            "  inflating: experiments/requirements.txt  \n",
            "  inflating: experiments/run_pipeline.sh  \n",
            "  inflating: experiments/run_stress_test.sh  \n",
            "   creating: experiments/src/\n",
            "  inflating: experiments/src/README.md  \n",
            "   creating: experiments/src/analysis/\n",
            "  inflating: experiments/src/analysis/README.md  \n",
            "  inflating: experiments/src/analysis/analyze_results.py  \n",
            "   creating: experiments/src/exp1_reset/\n",
            "  inflating: experiments/src/exp1_reset/1_baseline.py  \n",
            "  inflating: experiments/src/exp1_reset/2_train_sft.py  \n",
            "  inflating: experiments/src/exp1_reset/3_train_rl.py  \n",
            "  inflating: experiments/src/exp1_reset/4_verify_reset.py  \n",
            "  inflating: experiments/src/exp1_reset/README.md  \n",
            "   creating: experiments/src/exp2_rlae/\n",
            "  inflating: experiments/src/exp2_rlae/README.md  \n",
            "  inflating: experiments/src/exp2_rlae/elimination_test.py  \n",
            "   creating: experiments/src/exp3_svar/\n",
            "  inflating: experiments/src/exp3_svar/README.md  \n",
            "  inflating: experiments/src/exp3_svar/perturbation.py  \n",
            "   creating: experiments/src/exp4_stress/\n",
            "  inflating: experiments/src/exp4_stress/README.md  \n",
            "  inflating: experiments/src/exp4_stress/stress_single_run.py  \n",
            "   creating: experiments/src/exp5_comparison/\n",
            "  inflating: experiments/src/exp5_comparison/irreversibility_test.py  \n",
            "   creating: experiments/src/utils/\n",
            "  inflating: experiments/src/utils/README.md  \n",
            "  inflating: experiments/src/utils/browser_app.py  \n",
            "  inflating: experiments/src/utils/metrics.py  \n",
            "  inflating: experiments/src/utils/model.py  \n",
            "   creating: experiments/src/verification/\n",
            "  inflating: experiments/src/verification/README.md  \n",
            "  inflating: experiments/src/verification/robustness_suite.py  \n",
            "  inflating: index.html              \n",
            "   creating: project-scope/\n",
            "  inflating: project-scope/README.md  \n",
            "  inflating: project-scope/rlae-svar-doc.pdf  \n",
            "  inflating: project-scope/svar-doc.pdf  \n",
            "   creating: reports/\n",
            "  inflating: reports/README.md       \n",
            "  inflating: reports/report_2025-12-31.md  \n",
            "  inflating: reports/report_2025-12-31.pdf  \n"
          ]
        }
      ],
      "source": [
        "# C0 - [Environment & Imports]\n",
        "# 1. Upload your 'research.zip' using the file sidebar\n",
        "# 2. Extract the core\n",
        "!unzip REVA4-Research-Lab-Cloud.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0-mount",
        "outputId": "d73967d1-1df6-40c0-a377-983801669bff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/experiments\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m518.9/518.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# C0 - [Environment & Imports]\n",
        "%cd experiments\n",
        "!pip install -q -r requirements.txt\n",
        "!pip install -q gradio psutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0-gpu-check",
        "outputId": "a47afb3a-126e-436e-8385-dc9532cad33f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA Available: True\n",
            "Frozen Core Device: Tesla T4\n",
            "Memory Available: 15.83 GB\n"
          ]
        }
      ],
      "source": [
        "# C0 - [Environment & Imports]\n",
        "import torch\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Frozen Core Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory Available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxA6IC6ZTa2j"
      },
      "source": [
        "# Step 2: Determinism (C1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1-seed",
        "outputId": "cb545b71-a81b-4a80-ea74-043525313696"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Global seed locked to: 1337\n"
          ]
        }
      ],
      "source": [
        "# C1 - [Seed + Determinism]\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def set_global_seed(seed=1337):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    print(f\"Global seed locked to: {seed}\")\n",
        "\n",
        "set_global_seed(1337)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAtia7IQTa2k"
      },
      "source": [
        "# Step 3: Core Baseline (C2/C3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa-7-Um2A30e",
        "outputId": "41496491-aefe-4024-e06b-c43a9b961015"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-11 18:51:28.766540: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768157488.798056    2113 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768157488.807873    2113 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768157488.830585    2113 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768157488.830618    2113 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768157488.830623    2113 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768157488.830631    2113 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-11 18:51:28.837629: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "=== STARTING EXPERIMENT 1.B: BASELINE RUN (Hardened) ===\n",
            "GPU Memory: 0.00MB allocated, 0.00MB reserved\n",
            "Loading Base Model: Qwen/Qwen2.5-3B-Instruct\n",
            "config.json: 100% 661/661 [00:00<00:00, 5.99MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "model.safetensors.index.json: 35.6kB [00:00, 132MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/3.97G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 0.00/2.20G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 952k/3.97G [00:02<2:20:10, 472kB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 5.46M/2.20G [00:02<13:58, 2.62MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 4.83M/3.97G [00:02<22:31, 2.93MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 23.9M/3.97G [00:02<03:36, 18.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   1% 28.8M/2.20G [00:02<02:14, 16.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 63.3M/3.97G [00:02<01:11, 54.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   3% 57.6M/2.20G [00:02<01:12, 29.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 96.0M/3.97G [00:02<00:56, 68.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   3% 72.4M/2.20G [00:03<01:04, 33.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   6% 143M/2.20G [00:03<00:31, 64.6MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 129M/3.97G [00:03<01:20, 47.6MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   7% 156M/2.20G [00:04<00:47, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   7% 165M/2.20G [00:04<00:47, 43.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 147M/3.97G [00:04<01:54, 33.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  10% 210M/2.20G [00:04<00:29, 67.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 164M/3.97G [00:05<02:21, 26.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  10% 223M/2.20G [00:06<00:51, 38.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  13% 291M/2.20G [00:06<00:25, 74.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 174M/3.97G [00:06<02:34, 24.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  14% 318M/2.20G [00:06<00:26, 70.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 225M/3.97G [00:06<01:24, 44.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 276M/3.97G [00:07<00:59, 62.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  16% 360M/2.20G [00:07<00:25, 73.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 343M/3.97G [00:07<00:37, 97.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 370M/3.97G [00:07<00:35, 100MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  17% 377M/2.20G [00:08<00:34, 52.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 435M/3.97G [00:08<00:29, 121MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  18% 392M/2.20G [00:08<00:30, 60.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  20% 437M/2.20G [00:08<00:20, 84.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 513M/3.97G [00:09<00:44, 77.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  23% 500M/2.20G [00:09<00:26, 64.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 581M/3.97G [00:09<00:32, 104MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 639M/3.97G [00:09<00:24, 134MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  24% 523M/2.20G [00:09<00:26, 63.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  24% 536M/2.20G [00:10<00:27, 61.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 675M/3.97G [00:10<00:26, 123MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  25% 556M/2.20G [00:10<00:24, 66.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 728M/3.97G [00:10<00:24, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 805M/3.97G [00:10<00:19, 160MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  26% 574M/2.20G [00:11<00:31, 51.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 833M/3.97G [00:12<00:37, 84.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  29% 647M/2.20G [00:12<00:26, 59.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 904M/3.97G [00:12<00:25, 122MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  30% 656M/2.20G [00:12<00:28, 54.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 971M/3.97G [00:12<00:22, 131MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.09G/3.97G [00:14<00:36, 78.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.30G/3.97G [00:16<00:23, 115MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  33% 723M/2.20G [00:16<00:54, 27.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.41G/3.97G [00:16<00:19, 130MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  36% 790M/2.20G [00:17<00:39, 36.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.49G/3.97G [00:17<00:20, 121MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  39% 859M/2.20G [00:17<00:24, 55.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  40% 885M/2.20G [00:17<00:21, 62.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.55G/3.97G [00:17<00:18, 128MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.59G/3.97G [00:18<00:19, 124MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  41% 907M/2.20G [00:18<00:26, 49.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  42% 935M/2.20G [00:18<00:20, 61.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  43% 957M/2.20G [00:19<00:25, 49.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 1.61G/3.97G [00:19<00:33, 69.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 1.64G/3.97G [00:19<00:31, 72.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  47% 1.04G/2.20G [00:20<00:17, 67.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 1.71G/3.97G [00:20<00:23, 96.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 1.74G/3.97G [00:20<00:22, 98.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 1.81G/3.97G [00:20<00:15, 136MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  48% 1.06G/2.20G [00:20<00:21, 54.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  48% 1.07G/2.20G [00:21<00:21, 52.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 1.85G/3.97G [00:21<00:17, 120MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  50% 1.11G/2.20G [00:21<00:18, 59.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 1.93G/3.97G [00:21<00:17, 120MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  54% 1.18G/2.20G [00:21<00:11, 87.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 1.95G/3.97G [00:22<00:20, 96.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  54% 1.20G/2.20G [00:22<00:12, 81.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  56% 1.24G/2.20G [00:23<00:21, 45.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.01G/3.97G [00:27<01:07, 29.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.02G/3.97G [00:27<01:06, 29.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  58% 1.28G/2.20G [00:27<00:39, 23.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  58% 1.28G/2.20G [00:27<00:38, 23.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.03G/3.97G [00:27<01:12, 26.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  61% 1.34G/2.20G [00:28<00:22, 39.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.04G/3.97G [00:28<01:16, 25.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  64% 1.41G/2.20G [00:28<00:14, 52.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  65% 1.43G/2.20G [00:29<00:13, 55.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.05G/3.97G [00:29<01:28, 21.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.06G/3.97G [00:29<01:16, 25.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.07G/3.97G [00:29<01:05, 29.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  68% 1.50G/2.20G [00:29<00:10, 66.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.09G/3.97G [00:29<00:52, 35.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.12G/3.97G [00:30<00:32, 56.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.17G/3.97G [00:30<00:21, 82.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.21G/3.97G [00:31<00:25, 69.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.23G/3.97G [00:31<00:26, 66.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.24G/3.97G [00:31<00:29, 58.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  71% 1.56G/2.20G [00:32<00:13, 46.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.28G/3.97G [00:32<00:22, 75.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.31G/3.97G [00:32<00:18, 90.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.37G/3.97G [00:32<00:10, 145MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  74% 1.62G/2.20G [00:32<00:10, 54.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 2.46G/3.97G [00:33<00:12, 117MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 2.53G/3.97G [00:33<00:11, 130MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 2.55G/3.97G [00:37<00:40, 34.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  77% 1.69G/2.20G [00:37<00:18, 27.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 2.66G/3.97G [00:37<00:20, 62.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 2.74G/3.97G [00:43<00:43, 28.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  80% 1.75G/2.20G [00:43<00:24, 18.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 2.79G/3.97G [00:43<00:33, 34.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  83% 1.82G/2.20G [00:44<00:15, 24.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 2.84G/3.97G [00:44<00:28, 40.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  85% 1.88G/2.20G [00:44<00:10, 32.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 2.87G/3.97G [00:44<00:25, 43.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  87% 1.91G/2.20G [00:45<00:08, 36.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 2.89G/3.97G [00:45<00:24, 43.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  90% 1.98G/2.20G [00:45<00:04, 48.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 2.94G/3.97G [00:46<00:24, 41.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  92% 2.02G/2.20G [00:46<00:04, 43.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.00G/3.97G [00:47<00:16, 58.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.08G/3.97G [00:47<00:10, 83.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.13G/3.97G [00:47<00:08, 101MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  94% 2.07G/2.20G [00:48<00:03, 38.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 3.20G/3.97G [00:49<00:13, 58.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  97% 2.14G/2.20G [00:49<00:01, 41.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 3.32G/3.97G [00:50<00:07, 91.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 3.41G/3.97G [00:50<00:04, 118MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 3.44G/3.97G [00:50<00:04, 121MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 3.51G/3.97G [00:50<00:02, 157MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 3.58G/3.97G [00:51<00:02, 176MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 3.64G/3.97G [00:51<00:01, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 3.71G/3.97G [00:51<00:01, 211MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors: 100% 2.20G/2.20G [00:51<00:00, 42.6MB/s]\n",
            "\n",
            "model-00001-of-00002.safetensors:  95% 3.78G/3.97G [00:52<00:01, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 3.83G/3.97G [00:52<00:00, 219MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 3.90G/3.97G [00:52<00:00, 229MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 3.97G/3.97G [00:52<00:00, 75.0MB/s]\n",
            "Fetching 2 files: 100% 2/2 [00:53<00:00, 26.60s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:19<00:00,  9.84s/it]\n",
            "generation_config.json: 100% 242/242 [00:00<00:00, 2.30MB/s]\n",
            "tokenizer_config.json: 7.30kB [00:00, 34.2MB/s]\n",
            "vocab.json: 2.78MB [00:00, 57.7MB/s]\n",
            "merges.txt: 1.67MB [00:00, 137MB/s]\n",
            "tokenizer.json: 7.03MB [00:00, 178MB/s]\n",
            "Base model loaded and FROZEN.\n",
            "Processing p1...\n",
            "Processing p2...\n",
            "Processing p3...\n",
            "Processing p4...\n",
            "Processing p5...\n",
            "Processing p6...\n",
            "Processing p7...\n",
            "Processing p8...\n",
            "Processing p9...\n",
            "Processing p10...\n",
            "=== BASELINE RUN COMPLETE ===\n"
          ]
        }
      ],
      "source": [
        "# C2 - [Base Model Load] & C3 - [Prompt & Dataset Load]\n",
        "# Phase 1: Establish Frozen Core Baseline\n",
        "!python src/exp1_reset/1_baseline.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uLAgRuoTa2l"
      },
      "source": [
        "# Step 4: Adapter Development (C4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnROMZamBbIW",
        "outputId": "8f83fcdf-2ec8-45d6-d72e-9e8e935617f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-11 19:06:50.006202: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768158410.130364    6149 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768158410.181881    6149 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768158410.290974    6149 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768158410.291023    6149 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768158410.291031    6149 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768158410.291038    6149 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-11 19:06:50.317058: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "=== STARTING EXPERIMENT 1.C: LoRA SFT TRAINING ===\n",
            "Loading Base Model: Qwen/Qwen2.5-3B-Instruct\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100% 2/2 [00:25<00:00, 12.90s/it]\n",
            "Base model loaded and FROZEN.\n",
            "Attaching NEW LoRA adapters...\n",
            "trainable params: 1,843,200 || all params: 3,087,781,888 || trainable%: 0.0597\n",
            "Adding EOS to train dataset: 100% 30/30 [00:00<00:00, 1270.27 examples/s]\n",
            "Tokenizing train dataset: 100% 30/30 [00:00<00:00, 623.57 examples/s]\n",
            "Truncating train dataset: 100% 30/30 [00:00<00:00, 6656.57 examples/s]\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
            "{'loss': 2.5234, 'grad_norm': 2.452191114425659, 'learning_rate': 0.0002, 'entropy': 1.032120406627655, 'num_tokens': 300.0, 'mean_token_accuracy': 0.5731980055570602, 'epoch': 0.13}\n",
            "{'loss': 2.4352, 'grad_norm': 2.2818241119384766, 'learning_rate': 0.00019166666666666667, 'entropy': 1.071472778916359, 'num_tokens': 600.0, 'mean_token_accuracy': 0.6257761716842651, 'epoch': 0.27}\n",
            "{'loss': 2.6622, 'grad_norm': 2.657202959060669, 'learning_rate': 0.00018333333333333334, 'entropy': 1.0564329326152802, 'num_tokens': 867.0, 'mean_token_accuracy': 0.582227423787117, 'epoch': 0.4}\n",
            "{'loss': 1.8647, 'grad_norm': 2.44107985496521, 'learning_rate': 0.000175, 'entropy': 0.8211704045534134, 'num_tokens': 1170.0, 'mean_token_accuracy': 0.6833862811326981, 'epoch': 0.53}\n",
            "{'loss': 2.3143, 'grad_norm': 2.512590169906616, 'learning_rate': 0.0001666666666666667, 'entropy': 1.1471010744571686, 'num_tokens': 1446.0, 'mean_token_accuracy': 0.5808579623699188, 'epoch': 0.67}\n",
            "{'loss': 1.9058, 'grad_norm': 2.069953203201294, 'learning_rate': 0.00015833333333333332, 'entropy': 1.1401598453521729, 'num_tokens': 1759.0, 'mean_token_accuracy': 0.6358791291713715, 'epoch': 0.8}\n",
            "{'loss': 1.8785, 'grad_norm': 2.0069420337677, 'learning_rate': 0.00015000000000000001, 'entropy': 1.2330998480319977, 'num_tokens': 2078.0, 'mean_token_accuracy': 0.6043907999992371, 'epoch': 0.93}\n",
            "{'loss': 1.5066, 'grad_norm': 2.0404820442199707, 'learning_rate': 0.00014166666666666668, 'entropy': 1.1200025081634521, 'num_tokens': 2215.0, 'mean_token_accuracy': 0.7170329689979553, 'epoch': 1.0}\n",
            "{'loss': 1.7884, 'grad_norm': 2.105191469192505, 'learning_rate': 0.00013333333333333334, 'entropy': 1.2272245734930038, 'num_tokens': 2488.0, 'mean_token_accuracy': 0.656160980463028, 'epoch': 1.13}\n",
            "{'loss': 1.3883, 'grad_norm': 1.6651374101638794, 'learning_rate': 0.000125, 'entropy': 1.1947086602449417, 'num_tokens': 2778.0, 'mean_token_accuracy': 0.7463536560535431, 'epoch': 1.27}\n",
            "{'loss': 1.6051, 'grad_norm': 1.8361719846725464, 'learning_rate': 0.00011666666666666668, 'entropy': 1.3558610379695892, 'num_tokens': 3068.0, 'mean_token_accuracy': 0.6455531418323517, 'epoch': 1.4}\n",
            "{'loss': 1.4238, 'grad_norm': 1.8245192766189575, 'learning_rate': 0.00010833333333333333, 'entropy': 1.3304720520973206, 'num_tokens': 3367.0, 'mean_token_accuracy': 0.6797150075435638, 'epoch': 1.53}\n",
            "{'loss': 1.5237, 'grad_norm': 1.6824588775634766, 'learning_rate': 0.0001, 'entropy': 1.4264875054359436, 'num_tokens': 3672.0, 'mean_token_accuracy': 0.6804529428482056, 'epoch': 1.67}\n",
            "{'loss': 1.4755, 'grad_norm': 1.635385513305664, 'learning_rate': 9.166666666666667e-05, 'entropy': 1.3125236630439758, 'num_tokens': 3983.0, 'mean_token_accuracy': 0.6841530650854111, 'epoch': 1.8}\n",
            "{'loss': 1.5455, 'grad_norm': 1.599764108657837, 'learning_rate': 8.333333333333334e-05, 'entropy': 1.4260684549808502, 'num_tokens': 4278.0, 'mean_token_accuracy': 0.6764720678329468, 'epoch': 1.93}\n",
            "{'loss': 1.4533, 'grad_norm': 1.7878882884979248, 'learning_rate': 7.500000000000001e-05, 'entropy': 1.3345709443092346, 'num_tokens': 4430.0, 'mean_token_accuracy': 0.6653225719928741, 'epoch': 2.0}\n",
            "{'loss': 1.5222, 'grad_norm': 1.5775846242904663, 'learning_rate': 6.666666666666667e-05, 'entropy': 1.405718833208084, 'num_tokens': 4730.0, 'mean_token_accuracy': 0.6623184084892273, 'epoch': 2.13}\n",
            "{'loss': 1.377, 'grad_norm': 1.7092026472091675, 'learning_rate': 5.833333333333334e-05, 'entropy': 1.418437898159027, 'num_tokens': 5009.0, 'mean_token_accuracy': 0.6938473433256149, 'epoch': 2.27}\n",
            "{'loss': 1.3061, 'grad_norm': 1.983530879020691, 'learning_rate': 5e-05, 'entropy': 1.3177426755428314, 'num_tokens': 5305.0, 'mean_token_accuracy': 0.7528885751962662, 'epoch': 2.4}\n",
            "{'loss': 1.2071, 'grad_norm': 1.4978207349777222, 'learning_rate': 4.166666666666667e-05, 'entropy': 1.1882629245519638, 'num_tokens': 5604.0, 'mean_token_accuracy': 0.7701838612556458, 'epoch': 2.53}\n",
            "{'loss': 1.2599, 'grad_norm': 1.659284234046936, 'learning_rate': 3.3333333333333335e-05, 'entropy': 1.1816698759794235, 'num_tokens': 5916.0, 'mean_token_accuracy': 0.7317370176315308, 'epoch': 2.67}\n",
            "{'loss': 1.3643, 'grad_norm': 1.5029352903366089, 'learning_rate': 2.5e-05, 'entropy': 1.4488137662410736, 'num_tokens': 6200.0, 'mean_token_accuracy': 0.7334326952695847, 'epoch': 2.8}\n",
            "{'loss': 1.2539, 'grad_norm': 1.6532328128814697, 'learning_rate': 1.6666666666666667e-05, 'entropy': 1.1330857574939728, 'num_tokens': 6519.0, 'mean_token_accuracy': 0.786704495549202, 'epoch': 2.93}\n",
            "{'loss': 1.4604, 'grad_norm': 2.191185235977173, 'learning_rate': 8.333333333333334e-06, 'entropy': 1.480462670326233, 'num_tokens': 6645.0, 'mean_token_accuracy': 0.7551499307155609, 'epoch': 3.0}\n",
            "{'train_runtime': 82.492, 'train_samples_per_second': 1.091, 'train_steps_per_second': 0.291, 'train_loss': 1.6685606588919957, 'epoch': 3.0}\n",
            "100% 24/24 [01:22<00:00,  3.44s/it]\n",
            "Saving SFT adapter to /content/experiments/src/exp1_reset/../../models/lora_sft\n",
            "=== SFT TRAINING COMPLETE ===\n"
          ]
        }
      ],
      "source": [
        "# C4 - [Adapter Development]\n",
        "# Phase 2: Behavioral Mounting (SFT Training)\n",
        "!python src/exp1_reset/2_train_sft.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Al7kqarG08u",
        "outputId": "26e2bdd9-1c02-45ce-f693-b6b1a07f210b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-11 19:10:19.277018: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768158619.296795    7121 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768158619.302736    7121 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768158619.317801    7121 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768158619.317827    7121 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768158619.317831    7121 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768158619.317834    7121 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-11 19:10:19.322385: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "=== STARTING EXPERIMENT 1.D: LoRA RL (DPO) TRAINING ===\n",
            "Loading Base Model: Qwen/Qwen2.5-3B-Instruct\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100% 2/2 [00:22<00:00, 11.48s/it]\n",
            "Base model loaded and FROZEN.\n",
            "Extracting prompt in train dataset: 100% 2/2 [00:00<00:00, 71.25 examples/s]\n",
            "Applying chat template to train dataset: 100% 2/2 [00:00<00:00, 730.21 examples/s]\n",
            "Tokenizing train dataset: 100% 2/2 [00:00<00:00, 250.28 examples/s]\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
            "  0% 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "{'loss': 0.3816, 'grad_norm': 6.5133209228515625, 'learning_rate': 1e-05, 'rewards/chosen': 1.391350269317627, 'rewards/rejected': 0.6248912811279297, 'rewards/accuracies': 1.0, 'rewards/margins': 0.7664589285850525, 'logps/chosen': -84.37250518798828, 'logps/rejected': -64.3589859008789, 'logits/chosen': 0.011427301913499832, 'logits/rejected': 0.3757537603378296, 'epoch': 1.0}\n",
            "{'loss': 0.339, 'grad_norm': 5.615954399108887, 'learning_rate': 6.666666666666667e-06, 'rewards/chosen': 1.4875965118408203, 'rewards/rejected': 0.5799495577812195, 'rewards/accuracies': 1.0, 'rewards/margins': 0.907646894454956, 'logps/chosen': -83.41004180908203, 'logps/rejected': -64.80840301513672, 'logits/chosen': 0.023337479680776596, 'logits/rejected': 0.37637588381767273, 'epoch': 2.0}\n",
            "{'loss': 0.3403, 'grad_norm': 5.5914201736450195, 'learning_rate': 3.3333333333333333e-06, 'rewards/chosen': 1.4916718006134033, 'rewards/rejected': 0.5887439846992493, 'rewards/accuracies': 1.0, 'rewards/margins': 0.9029277563095093, 'logps/chosen': -83.36929321289062, 'logps/rejected': -64.720458984375, 'logits/chosen': 0.03319719433784485, 'logits/rejected': 0.3688274621963501, 'epoch': 3.0}\n",
            "{'train_runtime': 7.1325, 'train_samples_per_second': 0.841, 'train_steps_per_second': 0.421, 'train_loss': 0.3536400993665059, 'epoch': 3.0}\n",
            "100% 3/3 [00:07<00:00,  2.38s/it]\n",
            "Saving RL adapter to /content/experiments/src/exp1_reset/../../models/lora_rl\n",
            "=== RL TRAINING COMPLETE ===\n"
          ]
        }
      ],
      "source": [
        "# C4 - [Adapter Development]\n",
        "# Phase 3: Adaptive Environment Optimization (RL Training)\n",
        "!python src/exp1_reset/3_train_rl.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvs8w1o6Ta2m"
      },
      "source": [
        "# Step 5: The Structural Proof (C5‚ÄîC8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I-aAMqqdo6i",
        "outputId": "c0e8e4ab-9f57-41b7-e949-17d164e91aa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-01-11 19:11:51.331911: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768158711.353875    7538 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768158711.360132    7538 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768158711.380233    7538 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768158711.380258    7538 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768158711.380261    7538 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768158711.380265    7538 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-11 19:11:51.387582: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading Base Model: Qwen/Qwen2.5-3B-Instruct\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100% 2/2 [00:22<00:00, 11.29s/it]\n",
            "Base model loaded and FROZEN.\n",
            "\n",
            "============================================================\n",
            " SECTION 1: UNSTRUCTURED WEIGHT MUTATION (SIMULATED NOISE) \n",
            "============================================================\n",
            "Loading Base Model: Qwen/Qwen2.5-3B-Instruct\n",
            "Loading checkpoint shards: 100% 2/2 [00:22<00:00, 11.29s/it]\n",
            "Base model loaded and FROZEN.\n",
            "!!! CRITICAL: Simulating Direct Weight Mutation (Intensity=0.01) !!!\n",
            "SEC1 Peak KL: 10.4300\n",
            "!!! SEC1 RECOVERABILITY FACTOR: 0.00% !!!\n",
            "\n",
            "============================================================\n",
            " SECTION 2: STRUCTURED WEIGHT MUTATION (REAL GRADIENTS) \n",
            "============================================================\n",
            "Loading Base Model: Qwen/Qwen2.5-3B-Instruct\n",
            "Loading checkpoint shards: 100% 2/2 [00:23<00:00, 11.73s/it]\n",
            "Base model loaded and FROZEN.\n",
            "!!! CRITICAL: Executing Real Gradient-Based Mutation (Steps=10) !!!\n",
            "--- [TRAINING ENGINE]: Optimizing weights for task adaptation...\n",
            "    Step 1/10 | Loss: 2.6112\n",
            "    Step 2/10 | Loss: 1.0287\n",
            "    Step 3/10 | Loss: 1.1072\n",
            "    Step 4/10 | Loss: 0.7236\n",
            "    Step 5/10 | Loss: 1.1023\n",
            "    Step 6/10 | Loss: 0.7991\n",
            "    Step 7/10 | Loss: 1.1429\n",
            "    Step 8/10 | Loss: 0.8476\n",
            "    Step 9/10 | Loss: 0.8224\n",
            "    Step 10/10 | Loss: 1.1426\n",
            "--- [TRAINING ENGINE]: Mutation Complete. Core weights have been permanently drifted.\n",
            "SEC2 Peak KL: 0.2011\n",
            "!!! SEC2 RECOVERABILITY FACTOR: 0.00% !!!\n",
            "\n",
            "============================================================\n",
            " SECTION 3: RLAE METHOD (ADAPTIVE ENVIRONMENT) \n",
            "============================================================\n",
            "Loading Base Model: Qwen/Qwen2.5-3B-Instruct\n",
            "Loading checkpoint shards: 100% 2/2 [00:19<00:00,  9.72s/it]\n",
            "Base model loaded and FROZEN.\n",
            "RLAE: Adapter active.\n",
            "SEC3 Peak KL (Active Behavior): 0.0217\n",
            "RLAE: Activating Kill Switch (Unmounting Adapter)...\n",
            "!!! [RESTORE RESULT]: [PASS] - Identity perfectly recovered. KL: 0.0000 !!!\n",
            "!!! SEC3 RECOVERABILITY FACTOR: 100.00% !!!\n"
          ]
        }
      ],
      "source": [
        "# C5 - [Weight Mutation] | C6 - [Native Reset] | C7 - [Unload] | C8 - [Metrics]\n",
        "!python src/exp5_comparison/irreversibility_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mandatory-experiments"
      },
      "source": [
        "# üü• Mandatory Validation Experiments (M1)\n",
        "\n",
        "## üü• M1 ‚Äî Repeatability / New Seed Run\n",
        "- **What changes:** ONLY the seed (C1).\n",
        "- **Flow:** C0 ‚Üí C1 (new seed) ‚Üí C2 ‚Üí C3 ‚Üí C4 ‚Üí C5 ‚Üí C6 ‚Üí C7 ‚Üí C8\n",
        "- **Goal:** Prove binary structural confirmation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5hGJFdpTa2n"
      },
      "source": [
        "# üîç Appendix - Diagnostic Components\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlj42mI5RvHp"
      },
      "outputs": [],
      "source": [
        "# ctest1-elimination-test\n",
        "!python src/exp2_rlae/elimination_test.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMme2j6TWsaV"
      },
      "outputs": [],
      "source": [
        "# ctest2-svar-perturbation\n",
        "!python src/exp3_svar/perturbation.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8Pw8YhgcN0R"
      },
      "outputs": [],
      "source": [
        "# ctest3-runtime-stress-test\n",
        "!python src/exp4_stress/stress_single_run.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-_RQK8FiJ0p"
      },
      "source": [
        "# ZIP SPRINTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2On5-kRmiRTk",
        "outputId": "0b6fe939-dd25-456c-e363-bf941bc3ad37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: logs/Sprint-3/ (stored 0%)\n",
            "  adding: logs/Sprint-3/exp5_comparison_results.json (deflated 76%)\n",
            "  adding: logs/Sprint-3/exp1_results.json (deflated 78%)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "sprint_dir = 'logs/Sprint-3'\n",
        "if not os.path.exists(sprint_dir):\n",
        "    os.makedirs(sprint_dir)\n",
        "    print(f\"Created directory: {sprint_dir}\")\n",
        "\n",
        "!zip -r Sprint-3.zip {sprint_dir}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
