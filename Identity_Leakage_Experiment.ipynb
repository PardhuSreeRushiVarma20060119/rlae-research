{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PardhuSreeRushiVarma20060119/AI-RDE-Repository/blob/main/Identity_Leakage_Experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üõ°Ô∏è RLAE & SVAR: Canonical Research Environment\n",
        "\n",
        "This notebook implements the full research lifecycle for **Runtime Low‚ÄëRank Adaptive Environments (RLAE)** and **Structural Variance Analysis for Robustness (SVAR)**.\n",
        "\n",
        "## üìñ Paradigms in Scope\n",
        "- **Frozen Core Invariance:** The base model foundation is immutable.\n",
        "- **Behavioral Sandboxing:** RL updates apply only to swappable LoRA artifacts.\n",
        "- **Runtime Governance:** Behaviors can be dynamically mounted, replaced, or destroyed.\n",
        "- **Diagnostic Surface:** Evaluation via structural perturbation (SVAR) and identity leakage detection."
      ],
      "metadata": {
        "id": "o2GboHN4-txI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 0: Deployment & Extraction\n",
        "**On your local machine, zip the folder: ```zip -r research.zip experiments/```.**\n",
        "\n",
        "**In a Colab cell, run:**"
      ],
      "metadata": {
        "id": "yjzD6N2L-6ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Upload your 'research.zip' using the file sidebar\n",
        "# 2. Extract the core\n",
        "!unzip research.zip"
      ],
      "metadata": {
        "id": "_jU4wr6L_P8S",
        "outputId": "77be0f59-3bf2-4e9e-d344-f916f0eca5a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  research.zip\n",
            "warning:  research.zip appears to use backslashes as path separators\n",
            "   creating: experiments/src/\n",
            "  inflating: experiments/cloud_notebook.ipynb  \n",
            "  inflating: experiments/experiments_bundle.zip  \n",
            "  inflating: experiments/GPU_SAFE_SHUTDOWN.md  \n",
            "  inflating: experiments/README.md   \n",
            "  inflating: experiments/requirements.txt  \n",
            "  inflating: experiments/run_pipeline.sh  \n",
            "  inflating: experiments/run_stress_test.sh  \n",
            "  inflating: experiments/data/fixed_prompts.json  \n",
            "  inflating: experiments/data/training_data.json  \n",
            "  inflating: experiments/src/analysis/analyze_results.py  \n",
            "  inflating: experiments/src/exp1_reset/1_baseline.py  \n",
            "  inflating: experiments/src/exp1_reset/2_train_sft.py  \n",
            "  inflating: experiments/src/exp1_reset/3_train_rl.py  \n",
            "  inflating: experiments/src/exp1_reset/4_verify_reset.py  \n",
            "  inflating: experiments/src/exp2_rlae/elimination_test.py  \n",
            "  inflating: experiments/src/exp3_svar/perturbation.py  \n",
            "  inflating: experiments/src/exp4_stress/stress_single_run.py  \n",
            "  inflating: experiments/src/utils/browser_app.py  \n",
            "  inflating: experiments/src/utils/metrics.py  \n",
            "  inflating: experiments/src/utils/model.py  \n",
            "  inflating: experiments/src/utils/__pycache__/browser_app.cpython-311.pyc  \n",
            "  inflating: experiments/src/verification/robustness_suite.py  \n",
            "  inflating: experiments/src/verification/__pycache__/robustness_suite.cpython-311.pyc  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd experiments"
      ],
      "metadata": {
        "id": "8i98cIDs_vS8",
        "outputId": "95edd0a6-3c5d-473e-c126-237d7bb7112c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/experiments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è Step 1: Environment Mounting\n",
        "Install dependencies and verify the **Frozen Core** (GPU) status.\n",
        "\n",
        "Run this in a cell to install the canonical stack (optimized for T4):\n"
      ],
      "metadata": {
        "id": "1YoBlBto_8o-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r requirements.txt\n",
        "!pip install -q gradio psutil"
      ],
      "metadata": {
        "id": "jftqqwaL_3iA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Frozen Core Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory Available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\") # Should show ~15-16 GB on a T4"
      ],
      "metadata": {
        "id": "UlZ3NmReAcRy",
        "outputId": "3c5c2c29-4ebf-45b8-a33c-afe11124d770",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available: True\n",
            "Frozen Core Device: Tesla T4\n",
            "Memory Available: 15.83 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß™ Experiment 1: Reset Integrity & Training Pipeline\n",
        "Goal: Detect **Identity Leakage**. We train a behavioral environment and then attempt to prove its total reversibility.\n",
        "\n",
        "## Step 2: The Research Pipeline (Sequential)\n",
        "Execute these commands in separate cells to build the behavioral artifacts:\n",
        "\n",
        "1. Establish Core Baseline:"
      ],
      "metadata": {
        "id": "wMVbmkCDA5dS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 1: Establish Frozen Core Baseline\n",
        "!python src/exp1_reset/1_baseline.py"
      ],
      "metadata": {
        "id": "sa-7-Um2A30e",
        "outputId": "4d20166f-6966-4a41-971b-20431e44bcd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-31 15:54:50.159875: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767196490.179474    6436 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767196490.185555    6436 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767196490.200931    6436 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767196490.200956    6436 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767196490.200960    6436 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767196490.200963    6436 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-31 15:54:50.205549: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "=== STARTING EXPERIMENT 1.B: BASELINE RUN (Hardened) ===\n",
            "GPU Memory: 0.00MB allocated, 0.00MB reserved\n",
            "Loading Base Model: Qwen/Qwen2.5-3B-Instruct\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100% 2/2 [00:19<00:00,  9.71s/it]\n",
            "Base model loaded and FROZEN.\n",
            "Processing p1...\n",
            "Processing p2...\n",
            "Processing p3...\n",
            "Processing p4...\n",
            "Processing p5...\n",
            "Processing p6...\n",
            "Processing p7...\n",
            "Processing p8...\n",
            "Processing p9...\n",
            "Processing p10...\n",
            "=== BASELINE RUN COMPLETE ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Mount Behavioral Environment (SFT + RL):"
      ],
      "metadata": {
        "id": "h9CaGV8cBSL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 2: Behavioral Mounting (SFT Training)\n",
        "!python src/exp1_reset/2_train_sft.py"
      ],
      "metadata": {
        "id": "NnROMZamBbIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f56db0-eaaf-47f5-ad3e-06c12e129f22"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-31 16:21:54.130105: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767198114.201720   13494 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767198114.216157   13494 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767198114.267088   13494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767198114.267140   13494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767198114.267149   13494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767198114.267157   13494 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-31 16:21:54.275403: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "=== STARTING EXPERIMENT 1.C: LoRA SFT TRAINING ===\n",
            "Loading Base Model: Qwen/Qwen2.5-3B-Instruct\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100% 2/2 [00:22<00:00, 11.42s/it]\n",
            "Base model loaded and FROZEN.\n",
            "Attaching NEW LoRA adapters...\n",
            "trainable params: 1,843,200 || all params: 3,087,781,888 || trainable%: 0.0597\n",
            "Adding EOS to train dataset: 100% 5/5 [00:00<00:00, 253.22 examples/s]\n",
            "Tokenizing train dataset: 100% 5/5 [00:00<00:00, 128.36 examples/s]\n",
            "Truncating train dataset: 100% 5/5 [00:00<00:00, 654.81 examples/s]\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
            "{'loss': 2.3911, 'grad_norm': 2.527466058731079, 'learning_rate': 0.0002, 'entropy': 0.7718720808625221, 'num_tokens': 318.0, 'mean_token_accuracy': 0.6359865739941597, 'epoch': 0.8}\n",
            "{'loss': 2.4906, 'grad_norm': 3.239818572998047, 'learning_rate': 0.0001666666666666667, 'entropy': 0.8672820329666138, 'num_tokens': 381.0, 'mean_token_accuracy': 0.6451612710952759, 'epoch': 1.0}\n",
            "{'loss': 2.0238, 'grad_norm': 2.372296094894409, 'learning_rate': 0.00013333333333333334, 'entropy': 0.735789567232132, 'num_tokens': 702.0, 'mean_token_accuracy': 0.6883469223976135, 'epoch': 1.8}\n",
            "{'loss': 3.0181, 'grad_norm': 3.937812089920044, 'learning_rate': 0.0001, 'entropy': 1.2474725246429443, 'num_tokens': 762.0, 'mean_token_accuracy': 0.508474588394165, 'epoch': 2.0}\n",
            "{'loss': 1.8306, 'grad_norm': 2.3476126194000244, 'learning_rate': 6.666666666666667e-05, 'entropy': 0.7827927619218826, 'num_tokens': 1083.0, 'mean_token_accuracy': 0.7013688236474991, 'epoch': 2.8}\n",
            "{'loss': 2.8348, 'grad_norm': 3.850775718688965, 'learning_rate': 3.3333333333333335e-05, 'entropy': 1.2845244407653809, 'num_tokens': 1143.0, 'mean_token_accuracy': 0.49152541160583496, 'epoch': 3.0}\n",
            "{'train_runtime': 16.5935, 'train_samples_per_second': 0.904, 'train_steps_per_second': 0.362, 'train_loss': 2.431491732597351, 'epoch': 3.0}\n",
            "100% 6/6 [00:16<00:00,  2.77s/it]\n",
            "Saving SFT adapter to /content/experiments/src/exp1_reset/../../models/lora_sft\n",
            "=== SFT TRAINING COMPLETE ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 3: Adaptive Environment Optimization (RL Training)\n",
        "!python src/exp1_reset/3_train_rl.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Al7kqarG08u",
        "outputId": "08c020c8-5264-4584-aa54-daa6976a23f8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-31 16:28:27.226392: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767198507.264000   15224 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767198507.275286   15224 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767198507.320465   15224 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767198507.320508   15224 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767198507.320516   15224 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767198507.320523   15224 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-31 16:28:27.327983: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "=== STARTING EXPERIMENT 1.D: LoRA RL (DPO) TRAINING ===\n",
            "Loading Base Model: Qwen/Qwen2.5-3B-Instruct\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100% 2/2 [00:21<00:00, 10.67s/it]\n",
            "Base model loaded and FROZEN.\n",
            "Extracting prompt in train dataset: 100% 2/2 [00:00<00:00, 40.46 examples/s]\n",
            "Applying chat template to train dataset: 100% 2/2 [00:00<00:00, 684.23 examples/s]\n",
            "Tokenizing train dataset: 100% 2/2 [00:00<00:00, 181.14 examples/s]\n",
            "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n",
            "  0% 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n",
            "{'loss': 0.5869, 'grad_norm': 5.8635029792785645, 'learning_rate': 1e-05, 'rewards/chosen': 0.36446380615234375, 'rewards/rejected': 0.13860130310058594, 'rewards/accuracies': 1.0, 'rewards/margins': 0.225862517952919, 'logps/chosen': -94.64137268066406, 'logps/rejected': -69.22188568115234, 'logits/chosen': -0.1753450334072113, 'logits/rejected': 0.08977536112070084, 'epoch': 1.0}\n",
            "{'loss': 0.5717, 'grad_norm': 5.59145450592041, 'learning_rate': 6.666666666666667e-06, 'rewards/chosen': 0.4186714291572571, 'rewards/rejected': 0.1580272763967514, 'rewards/accuracies': 1.0, 'rewards/margins': 0.2606441378593445, 'logps/chosen': -94.09928894042969, 'logps/rejected': -69.02762603759766, 'logits/chosen': -0.16934916377067566, 'logits/rejected': 0.09802539646625519, 'epoch': 2.0}\n",
            "{'loss': 0.5705, 'grad_norm': 5.485337257385254, 'learning_rate': 3.3333333333333333e-06, 'rewards/chosen': 0.4264698028564453, 'rewards/rejected': 0.1639575958251953, 'rewards/accuracies': 1.0, 'rewards/margins': 0.26251220703125, 'logps/chosen': -94.02130889892578, 'logps/rejected': -68.96832275390625, 'logits/chosen': -0.16355091333389282, 'logits/rejected': 0.08688119798898697, 'epoch': 3.0}\n",
            "{'train_runtime': 7.4438, 'train_samples_per_second': 0.806, 'train_steps_per_second': 0.403, 'train_loss': 0.5763753056526184, 'epoch': 3.0}\n",
            "100% 3/3 [00:07<00:00,  2.48s/it]\n",
            "Saving RL adapter to /content/experiments/src/exp1_reset/../../models/lora_rl\n",
            "=== RL TRAINING COMPLETE ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üõë REVERSIBILITY CHECK (Hard Reset)\n",
        "To validate **Principle 6 (Killability)**:\n",
        "1. Go to **Runtime** > **Restart Session**.\n",
        "2. Re-run Step 0 (Imports only).\n",
        "3. Run the verification cell below."
      ],
      "metadata": {
        "id": "LdRC84_sGc3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Phase 4: Detect Identity Leakage (Post-Unmount Check)\n",
        "!python src/exp1_reset/4_verify_reset.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHD7uhj5GfBr",
        "outputId": "377a7649-271b-42ab-821f-fc4b12104fac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-31 16:34:25.342579: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767198865.393622   16889 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767198865.407303   16889 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767198865.472743   16889 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767198865.472783   16889 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767198865.472791   16889 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767198865.472798   16889 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-31 16:34:25.480128: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "=== STARTING EXPERIMENT 1.E: POST-RESET CHECK (Hardened) ===\n",
            "GPU Memory: 0.00MB allocated, 0.00MB reserved\n",
            "Loading Base Model: Qwen/Qwen2.5-3B-Instruct\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading checkpoint shards: 100% 2/2 [00:24<00:00, 12.27s/it]\n",
            "Base model loaded and FROZEN.\n",
            "Processing p1...\n",
            "       - ILS: 0.0445 (HEALTHY)\n",
            "Processing p2...\n",
            "       - ILS: 0.0287 (HEALTHY)\n",
            "Processing p3...\n",
            "       - ILS: 0.0145 (HEALTHY)\n",
            "Processing p4...\n",
            "       - ILS: 0.0257 (HEALTHY)\n",
            "Processing p5...\n",
            "       - ILS: 0.0676 (LEAKAGE DETECTED)\n",
            "Processing p6...\n",
            "       - ILS: 0.0360 (HEALTHY)\n",
            "Processing p7...\n",
            "       - ILS: 0.0154 (HEALTHY)\n",
            "Processing p8...\n",
            "       - ILS: 0.0260 (HEALTHY)\n",
            "Processing p9...\n",
            "       - ILS: 0.0227 (HEALTHY)\n",
            "Processing p10...\n",
            "       - ILS: 0.0189 (HEALTHY)\n",
            "=== POST-RESET CHECK COMPLETE ===\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}